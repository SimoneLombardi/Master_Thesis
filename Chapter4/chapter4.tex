%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8
% THESIS CHAPTER

\chapter{Methodology}
\label{chap:fourth}
\graphicspath{{Chapter4/Figures/PNG/}{Chapter4/Figures/JPG/}{Chapter4/Figures/JPEG/}{Chapter4/Figures/}}
in this chapter I will describe in detail the mathematical computation performed by the control algorithm I developed. 

\section{Goal broadcasting}
The architecture works in a \textit{position reaching} framework, a goal position for the \textit{end effector} is sent to the robot and the algorithm tries to reach said position, with constraint given by other tasks.
The goal is sent using the \textit{action server} build in the \textit{JointRobotTP} class, in the form of two vectors:
\begin{align}
	\vec{r} = \begin{pmatrix}
			x \\
			y \\
			z
	\end{pmatrix}
	\hspace{8pt} \text{;} \hspace{8pt}
	\vec{\rho} = \begin{pmatrix}
		\phi \\
		\theta \\
		\psi
	\end{pmatrix}
\end{align}

The first represent the desired translation, and the desired rotation as \textit{roll, pitch, yaw} angles.
The projection frames of this vector to define the goal position and orientation could be either the \textit{end effector} frame, or, the \textit{kuka base} frame. This was done for experimental purposes, for easly sequencing different goals, or to repeat reaching tasks to a specific position in the environment.

For the orientation of the goal, $\vec{\rho}$ is used to compose the rotation matrix that is than projected on the desired frame:
\begin{align}
	\vec{R}_{goal} &= \vec{R}_{z}(\psi) \cdot \vec{R}_{y}(\theta) \cdot \vec{R}_{x}(\phi) \\[4pt]
	\langle\textit{kuka\_base}\rangle: \leftindex^{kb}{\vec{R}}_{goal} &= \vec{I} \cdot \vec{R}_{goal} \\
	\langle\textit{end\_effector}\rangle: \leftindex^{ee}{\vec{R}}_{goal} &= \vec{R}_{ee}^{kb} \cdot \vec{R}_{goal}
\end{align}
In the first case the projection matrix is the identity since $\langle\textit{kuka\_base}\rangle \equiv \langle\textit{world}\rangle$.
Same process is done for the translation vector:
\begin{align}
	\langle\textit{kuka\_base}\rangle: \leftindex^{kb}{\vec{r}}_{goal} &= \vec{0} + \vec{r}_{goal}\\
	\langle\textit{end\_effector}\rangle: \leftindex^{ee}{\vec{r}}_{goal} &= \vec{r}_{ee}^{kb} + \vec{r}_{goal}
\end{align}
Than the rotation matrix and the translation vector are use to publish the $\langle\textit{goal}\rangle$ in rviz.
\section{Task Priority}
Continuing the discussion from \ref{equat:TaskPrioritiClassic_generalSolution}, the classic task priority algorithm as explained in \cite{simetti2016novel} lacks the ability to smoothly activate and deactivate \textit{inequality} task when the robot is far from the activation region.
The approach that I implemented is based on the definition of a new \textit{regularized pseudo-inversion operator} that integrates the \textit{activation function} as a weight matrix to modulate the intensity of the action taken for a specific task.
The operator is defined as:
\begin{equation}
	\vec{X}^{\#,\vec{A},\vec{Q}} \triangleq (\vec{X}^T\vec{A}\vec{X} + \eta(\vec{I}-\vec{Q})^T(\vec{I}-\vec{Q}) + \vec{V}^T\vec{P}\vec{V})^{\#} \vec{X}^T\vec{A}\vec{A}
	\label{equat:RegPseudoInverse_operator}
\end{equation}
where the matrix $\vec{V}$ is the right orthonormal matrix of the SVD decomposition for     $\vec{X}^T\vec{A}\vec{X}+\eta(\vec{I}-\vec{Q})^T(\vec{I}-\vec{Q})$.
The compact expression of the algorithm becomes, for the \textit{k-th} priority level:
\begin{equation}
	\begin{aligned}
		\vec{W}_k &= \vec{J}_k\vec{Q}_{k-1}(\vec{J}_k\vec{Q}_{k-1})^{\#,\vec{A}_k,\vec{Q}_{k-1}} \\
		\vec{Q}_k &= \vec{Q}_{k-1}(\vec{I}-(\vec{J}_k\vec{Q}_{k-1})^{\#,\vec{A}_k,\vec{I}}\vec{J}_k\vec{Q}_{k-1}) \\
		\vec{\rho}_k &= \vec{\rho}_{k-1} + \vec{Q}_{k-1}(\vec{J}_k\vec{Q}_{k-1})^{\#,\vec{A}_k,\vec{I}}\vec{W}_k(\vec{\dot{x}}-\vec{J}_k\vec{\rho}_{k-1})
	\end{aligned}
\end{equation}


\subsection{Task Description}
In this section I will describe the mathematical formulation of the task I implemented in my control loop. To simplify the notation all the matrices, if not stated otherwise, are projected on the $\langle\textit{kuka\_base}\rangle$ reference frame.
\subsubsection{End Effector minimum altitude}
This task is used to keep the end effector away from the floor.\\
\\ \\
\textbf{Task reference}:\\
\noindent 
The reference rate for this task is computed using the $z$ coordinate of the traslation from the $\langle\textit{kuka\_base}\rangle$ frame to $\langle\textit{end\_effector}\rangle$. 
\begin{equation}
	\textit{Reference rate: } \dot{\bar{x}}_z = \lambda \cdot (\vec{\bar{x}} + \delta - \vec{z}_{ee}^{kb})
\end{equation}
The complete vector has all zero exept on the $z$ coordinate.
\begin{equation}
	\textit{Reference rate: } \vec{\dot{\bar{x}}} = [0, 0, \dot{\bar{x}}_z, 0, 0, 0]^T
\end{equation}
\\
\noindent The \textit{Reference rate} is considered as the \textit{desired shape} of the derivative of the variable I want to control.
To be more precise:
\begin{itemize}
	\item if $x > \bar{x}$ then $\dot{x} < 0$
	\item if $x < \bar{x}$ then $\dot{x} > 0$
	\item if $x = \bar{x}$ then $\dot{x} = 0$
\end{itemize}
In the case of the \textit{Minimual altitude task} the variable I want to control is the $z$ of the \textit{end effector} of the robot, and to impose a minimum altitude $z_{min}$. Finally the $\delta$ keeps count of the activation region, meaning that the task will be smoothly activated starting from $z_{min} + \delta$ to $z_{min}$.
\\ \\
\noindent \textbf{Activation function}: \\
\noindent To avoid the abrupt activation of the task that could lead to chattering around the treshold, and more importantly to avoid the over constraining of the system we also add a smooth \textit{activation function}.

\begin{equation}
	a = 
	\begin{cases}
		1 &  x < x_{min} \\[5pt]
		\frac{1}{2}[(\cos(\pi\frac{x-x_{min}}{\delta})+1)] & x\in[x_{min},x_{min}+\delta] \\[5pt]
		0 &  x > x_{min} + \delta
	\end{cases}
\end{equation}

\begin{figure}[H]
	\centering
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{DecreasingActFcn.jpg}
		\caption{Generic function}
		\label{fig:DecreasingActFcn}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.49\textwidth}
		\includegraphics[width=\linewidth]{DecreasingActFcn_realValues.jpg}
		\caption{With realistic values}
		\label{fig:DecreasingActFcn_rv}
	\end{subfigure}
\end{figure}
In this case I used a $(6 \times 6)$ zero matrix as my activation function, than I inserted the value in the third position of the major diagonal, ending up with:
\begin{equation}
	\vec{A}_{min alt} = \textit{diag} (0, 0, a_z, 0, 0, 0)
\end{equation}
using $z_min = 0,30$\textit{m} as my lower limit and $\delta = 0,1$\textit{m}, and the function is tuned to yield $y \in [0,1]$.
\\ \\
\noindent \textbf{Task Jacobian}\\
\noindent For this task the jacobian matrix is equivalent to the geometric jacobian, computed up to the \textit{end effector} frame. Since the available methods of the classes \codetxt{darkgray}{KukaRobot} and \codetxt{darkgray}{UR10eRobot} compute the jacobians matrices in their respective base frames. Enumeratin the links of the whole robot as $lk_i=1 ... 12$\\
\begin{equation}
	\leftindex^{kb}{\vec{J}}_{6/kb} ; \leftindex^{ub}{\vec{J}}_{12/ub}
\end{equation}
\\
The complete trasformation for computing the Jacobian of the unified structure projected in the frame base is:
\\
\begin{equation}
	content...
\end{equation}


\subsubsection{Obstacle Avoidance}
% single point

% set based task

\subsubsection{End Effector Target}
